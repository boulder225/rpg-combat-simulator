---
phase: 02-creature-data-monte-carlo
plan: 06
type: execute
wave: 3
depends_on: ["02-02", "02-04", "02-05"]
files_modified:
  - src/output/report_generator.py
  - data/reports/.gitkeep
autonomous: true
user_setup: []

must_haves:
  truths:
    - "System generates dual output: terminal summary and markdown report"
    - "Reports include win rate with confidence intervals and difficulty rating"
    - "Reports are saved to data/reports/ with timestamped filenames"
  artifacts:
    - path: "src/output/report_generator.py"
      provides: "Report generation with terminal and markdown output"
      exports: ["ReportGenerator"]
    - path: "data/reports/.gitkeep"
      provides: "Reports directory structure"
      contains: ".gitkeep"
  key_links:
    - from: "src/output/report_generator.py"
      to: "src/analysis/difficulty.py"
      via: "difficulty rating calculation"
      pattern: "calculate_difficulty_rating"
    - from: "src/output/report_generator.py"
      to: "data/reports/"
      via: "file output"
      pattern: "open\\(f\\\"data/reports/.*\\.md\\\""

---

<objective>
Implement report generation system that produces both terminal summaries and detailed markdown reports with difficulty ratings.

Purpose: Provide DMs with comprehensive simulation results in both immediate terminal output and persistent markdown reports for session prep notes.
Output: Report generator that creates terminal summaries and timestamped markdown reports in data/reports/ directory.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-creature-data-monte-carlo/02-CONTEXT.md
@.planning/phases/02-creature-data-monte-carlo/02-RESEARCH.md

@src/analysis/difficulty.py
@src/simulation/batch_runner.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create report generator with dual output</name>
  <files>src/output/report_generator.py</files>
  <action>
Create ReportGenerator class that produces dual output (terminal + markdown):
- Constructor takes batch_results and simulation parameters
- generate_terminal_summary() method that:
  - Displays concise summary to terminal with win rate, CI, difficulty rating
  - Shows average combat duration for wins vs losses
  - Includes per-creature damage breakdown summary
  - Formats as: "Party wins: 69%-77% (95% CI) - Medium difficulty"
- generate_markdown_report() method that:
  - Creates detailed markdown report with timestamped filename in data/reports/
  - Includes full statistics: win rate, duration, damage breakdown, per-creature stats
  - Includes per-run outcomes table (not shown in terminal)
  - Uses proper markdown formatting with headers, tables, and sections
  - Returns the full report content as string
- save_markdown_report() method that saves report to file
- Uses calculate_difficulty_rating from src/analysis/difficulty.py
- Implements proper error handling for file operations
  </action>
  <verify>python -c "from src.output.report_generator import ReportGenerator; print('Report generator imported successfully')"</verify>
  <done>Report generator can produce both terminal summaries and detailed markdown reports</done>
</task>

<task type="auto">
  <name>Task 2: Create reports directory structure</name>
  <files>data/reports/.gitkeep</files>
  <action>
Create reports directory structure:
- Create data/reports/ directory if it doesn't exist
- Add .gitkeep file to ensure directory is tracked
- Ensure proper permissions for report file creation
- The directory should be alongside data/creatures/ and data/srd-cache/ for consistency
  </action>
  <verify>ls data/reports/.gitkeep</verify>
  <done>Reports directory exists with .gitkeep file and proper structure</done>
</task>

</tasks>

<verification>
- Terminal output shows win rate with confidence intervals and difficulty rating
- Markdown reports are saved to data/reports/ with timestamped filenames
- Reports include per-creature damage breakdown and per-run outcomes table
- Difficulty ratings are calculated and displayed correctly
</verification>

<success_criteria>
- Running batch simulation produces terminal output like "Party wins: 73% +/- 4% - Medium difficulty"
- Markdown report is saved to data/reports/ with timestamp like "2026-02-08_14-30-22_simulation_report.md"
- Report includes all required statistics: win rate, duration, damage breakdown, difficulty rating
</success_criteria>

<output>
After completion, create `.planning/phases/02-creature-data-monte-carlo/02-06-SUMMARY.md`
</output>