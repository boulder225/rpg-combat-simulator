---
phase: 05-spells-conditions-resume
plan: 03
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/io/checkpoint.py
  - src/simulation/batch_runner.py
  - src/simulation/monte_carlo.py
  - src/cli/batch_args.py
  - run.py
  - tests/test_checkpoint.py
autonomous: true

must_haves:
  truths:
    - "Checkpoint file saves runs_done, wins, and RNG state to JSON"
    - "Loading checkpoint restores exact RNG state so resumed simulation produces identical results"
    - "BatchRunner writes checkpoint every N runs (configurable, default 100)"
    - "CLI --resume flag loads checkpoint and skips already-completed runs"
    - "Resumed batch produces same final statistics as uninterrupted run (with same seed)"
  artifacts:
    - path: "src/io/checkpoint.py"
      provides: "Checkpoint save/load with JSON serialization"
      contains: "save_checkpoint"
    - path: "src/cli/batch_args.py"
      provides: "CLI --resume and --checkpoint-every flags"
      contains: "resume"
    - path: "run.py"
      provides: "Resume-aware batch entry point"
      contains: "resume"
  key_links:
    - from: "src/io/checkpoint.py"
      to: "src/simulation/monte_carlo.py"
      via: "MonteCarloSimulator uses checkpoint data to skip completed runs"
      pattern: "runs_done"
    - from: "src/simulation/batch_runner.py"
      to: "src/io/checkpoint.py"
      via: "BatchRunner calls save_checkpoint periodically"
      pattern: "save_checkpoint"
    - from: "run.py"
      to: "src/io/checkpoint.py"
      via: "CLI loads checkpoint on --resume"
      pattern: "load_checkpoint"
---

<objective>
Implement batch checkpoint/resume so interrupted simulations can restart from where they left off. A DM running 1000 simulations can Ctrl+C, then resume from the last checkpoint without losing progress.

Purpose: Satisfies success criterion 5 (LOG-02). Long-running batch simulations become resilient to interruption.

Output: `src/io/checkpoint.py` with save/load, checkpoint writes in batch_runner, `--resume` and `--checkpoint-every` CLI flags, tests for checkpoint roundtrip and resume correctness.
</objective>

<execution_context>
@/Users/enrico/.claude/get-shit-done/workflows/execute-plan.md
@/Users/enrico/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-spells-conditions-resume/05-RESEARCH.md
@src/simulation/monte_carlo.py
@src/simulation/batch_runner.py
@src/cli/batch_args.py
@run.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Checkpoint serialization module with save/load and roundtrip tests</name>
  <files>
    src/io/checkpoint.py
    tests/test_checkpoint.py
  </files>
  <action>
RED: Write tests in `tests/test_checkpoint.py`:
- `test_save_checkpoint_creates_file`: save checkpoint, verify file exists and is valid JSON
- `test_load_checkpoint_roundtrip`: save then load, verify runs_done, wins match
- `test_rng_state_roundtrip`: set random.seed(42), get state, save checkpoint, set random.seed(999) (clobber state), load checkpoint, verify random.random() == expected (matches original sequence)
- `test_checkpoint_format_version`: saved JSON contains "format_version": 1
- `test_load_nonexistent_file_raises`: load from non-existent path raises FileNotFoundError

GREEN: Create `src/io/checkpoint.py`:

```python
"""Checkpoint save/load for resumable batch simulations."""

import json
import random
from pathlib import Path


def save_checkpoint(path: Path, runs_done: int, wins: int, total_runs: int) -> None:
    """Save batch progress checkpoint to JSON file.

    Args:
        path: File path for checkpoint JSON
        runs_done: Number of runs completed so far
        wins: Number of party wins so far
        total_runs: Total runs requested (for progress display)
    """
    rng_state = random.getstate()
    data = {
        "format_version": 1,
        "runs_done": runs_done,
        "wins": wins,
        "total_runs": total_runs,
        "rng_version": rng_state[0],
        "rng_state": list(rng_state[1]),
        "rng_gauss": rng_state[2],
    }
    Path(path).write_text(json.dumps(data, indent=2))


def load_checkpoint(path: Path) -> dict:
    """Load batch progress checkpoint from JSON file.

    Restores Python random state to exact checkpoint position.

    Args:
        path: File path to checkpoint JSON

    Returns:
        Dict with runs_done, wins, total_runs

    Raises:
        FileNotFoundError: If checkpoint file doesn't exist
    """
    path = Path(path)
    if not path.exists():
        raise FileNotFoundError(f"Checkpoint file not found: {path}")

    data = json.loads(path.read_text())

    # Restore RNG state (tuple of ints, not list)
    random.setstate((
        data["rng_version"],
        tuple(data["rng_state"]),
        data["rng_gauss"],
    ))

    return {
        "runs_done": data["runs_done"],
        "wins": data["wins"],
        "total_runs": data["total_runs"],
    }
```

Key detail: `random.getstate()` returns `(3, tuple_of_625_ints, float_or_None)`. JSON serializes the tuple as a list. On load, convert back to tuple with `tuple(data["rng_state"])`. The version (3) and gauss_next are preserved exactly.
  </action>
  <verify>cd /Users/enrico/workspace/myobsidian/dnd-simulator && python -m pytest tests/test_checkpoint.py -v</verify>
  <done>Checkpoint saves/loads runs_done, wins, and RNG state; roundtrip preserves exact random sequence</done>
</task>

<task type="auto">
  <name>Task 2: Integrate checkpoint into batch runner and CLI</name>
  <files>
    src/simulation/monte_carlo.py
    src/simulation/batch_runner.py
    src/cli/batch_args.py
    run.py
    tests/test_checkpoint.py
  </files>
  <action>
**1. Add resume support to MonteCarloSimulator (`src/simulation/monte_carlo.py`):**

Add optional `resume_from` parameter to `run_simulation()`:

```python
def run_simulation(
    self, creatures, agent, seed=None, max_rounds=100, verbose=False,
    terrain=None, on_progress=None,
    resume_from: dict | None = None,  # {"runs_done": N, "wins": M}
) -> SimulationResults:
```

If `resume_from` is provided:
- Set `wins = resume_from["wins"]`, `total_runs = resume_from["runs_done"]`
- Skip the Phase 1 min_runs loop if total_runs >= min_runs (already done)
- Skip to Phase 2 progressive sampling (or continue min_runs from where left off)
- Do NOT call `random.seed(seed)` if resuming â€” the RNG state was already restored by `load_checkpoint()`

Modified flow:
```python
if resume_from:
    wins = resume_from["wins"]
    total_runs = resume_from["runs_done"]
    # RNG already restored by caller
else:
    if seed is not None:
        random.seed(seed)
    wins = 0
    total_runs = 0

# Phase 1: Run remaining minimum simulations
remaining_min = max(0, self.min_runs - total_runs)
for run_idx in range(remaining_min):
    # ... existing run logic ...

# Phase 2: Progressive sampling (no change, uses total_runs)
```

**2. Add checkpoint writes to BatchRunner (`src/simulation/batch_runner.py`):**

Add `checkpoint_path` and `checkpoint_every` parameters to `run_batch()`:

```python
def run_batch(
    self, creatures, agent, seed=None, max_rounds=100, terrain=None,
    on_progress=None,
    checkpoint_path=None,    # Path to write checkpoint file
    checkpoint_every=100,    # Write checkpoint every N runs
    resume_from=None,        # Resume data from load_checkpoint()
) -> BatchResults:
```

Pass `resume_from` through to `self.simulator.run_simulation(resume_from=resume_from)`.

For checkpoint writes, wrap the `on_progress` callback:

```python
original_progress = on_progress

def progress_with_checkpoint(runs_done, max_runs, wins):
    if checkpoint_path and runs_done > 0 and runs_done % checkpoint_every == 0:
        from src.io.checkpoint import save_checkpoint
        save_checkpoint(checkpoint_path, runs_done, wins, max_runs)
    if original_progress:
        original_progress(runs_done, max_runs, wins)

sim_results = self.simulator.run_simulation(
    ...,
    on_progress=progress_with_checkpoint,
    resume_from=resume_from,
)
```

**3. Add CLI flags to `src/cli/batch_args.py`:**

Add to BatchArgs dataclass:
```python
resume: Optional[str] = None        # Path to checkpoint file for resume
checkpoint_every: int = 100          # Write checkpoint every N runs
```

Add to argument parser:
```python
parser.add_argument(
    "--resume",
    type=str,
    default=None,
    metavar="CHECKPOINT",
    help="Resume batch from checkpoint file (e.g., checkpoint.json)"
)

parser.add_argument(
    "--checkpoint-every",
    type=int,
    default=100,
    metavar="N",
    help="Write checkpoint every N runs (default: 100)"
)
```

Wire to BatchArgs in the return statement: `resume=parsed.resume, checkpoint_every=parsed.checkpoint_every`

**4. Wire resume into `run.py`:**

In `run_batch_simulation()`, add resume_from parameter:

```python
def run_batch_simulation(creatures, agent, runs, seed=None, verbose=True, terrain=None,
                         resume_path=None, checkpoint_every=100):
```

At the start of the function:
```python
resume_from = None
checkpoint_path = Path("checkpoint.json")  # Default checkpoint path

if resume_path:
    from src.io.checkpoint import load_checkpoint
    resume_from = load_checkpoint(resume_path)
    print(f"Resuming from checkpoint: {resume_from['runs_done']}/{runs} runs done, {resume_from['wins']} wins")
    if seed is not None:
        print("Warning: --seed ignored when resuming (using checkpoint RNG state)")
```

Pass to runner:
```python
results = runner.run_batch(
    creatures, agent, seed=seed, terrain=terrain,
    checkpoint_path=checkpoint_path,
    checkpoint_every=checkpoint_every,
    resume_from=resume_from,
)
```

In `main()`, pass `resume_path=args.resume, checkpoint_every=args.checkpoint_every` to `run_batch_simulation`.

**5. Add integration test in `tests/test_checkpoint.py`:**
- `test_resume_produces_correct_count`: Run 50 runs with seed=42, save checkpoint at 25 via callback, load checkpoint, resume from 25 to 50, verify total_runs == 50
  </action>
  <verify>cd /Users/enrico/workspace/myobsidian/dnd-simulator && python -m pytest tests/test_checkpoint.py tests/ -v</verify>
  <done>--resume loads checkpoint and skips completed runs; --checkpoint-every writes periodic checkpoints; resumed simulation produces correct total run count; full test suite green</done>
</task>

</tasks>

<verification>
```bash
cd /Users/enrico/workspace/myobsidian/dnd-simulator

# Unit tests for checkpoint
python -m pytest tests/test_checkpoint.py -v

# Integration: run a batch, verify checkpoint file created
python run.py --party fighter.md --enemies goblin goblin --runs 200 --seed 42 --checkpoint-every 50
ls -la checkpoint.json

# Resume from checkpoint
python run.py --party fighter.md --enemies goblin goblin --runs 200 --resume checkpoint.json

# Full test suite
python -m pytest tests/ -v
```
</verification>

<success_criteria>
- Checkpoint JSON file created every N runs during batch simulation
- Checkpoint contains runs_done, wins, and exact RNG state
- --resume loads checkpoint, skips completed runs, continues from checkpoint
- Resumed batch reports correct total_runs and win_rate
- Warning printed when --seed used with --resume
- All existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-spells-conditions-resume/05-03-SUMMARY.md`
</output>
